{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "training_data_fp= \"datasets/housing/major_project/TrainingFeatures.json\"\n",
    "train_data= pd.read_json(training_data_fp,lines=True)\n",
    "\n",
    "big_list1=[]\n",
    "big_list2=[]\n",
    "\n",
    "for i in range(0,48101,1):\n",
    "    local_list=[]\n",
    "    local_list.append(train_data[\"text_length\"][i])\n",
    "    local_list.append(train_data[\"char_count\"][i])\n",
    "    local_list.append(train_data[\"word_count\"][i])\n",
    "    local_list.append(train_data[\"unique_word_count\"][i])\n",
    "    local_list.append(train_data[\"sent_count\"][i])\n",
    "    local_list.append(train_data[\"ari\"][i])\n",
    "    local_list.append(train_data[\"stars\"][i])\n",
    "    big_list1.append(local_list)    \n",
    "\n",
    "X_train= np.array(big_list1)\n",
    "\n",
    "\n",
    "outcome_var_fp= \"datasets/housing/major_project/outcome_variable_train.json\"\n",
    "outcome_var= pd.read_json(outcome_var_fp,lines=True)\n",
    "\n",
    "for i in range(0,48101,1):\n",
    "    big_list2.append(outcome_var[\"outcome_var\"][i])\n",
    "    \n",
    "Y_train= np.array(big_list2)    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "coef_ is only available when using a linear kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-15300750758d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mcoef_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcoef_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'linear'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m             raise AttributeError('coef_ is only available when using a '\n\u001b[0m\u001b[0;32m    466\u001b[0m                                  'linear kernel')\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: coef_ is only available when using a linear kernel"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "model = svm.SVR()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70287179586409176"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict([[-0.00022349,  0.0003068 , -0.00080543,  0.00267085,  0.00886399, 0.00244912,  0.05713286]]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48101\n",
      "[ 84.9929416] % for training dataset\n"
     ]
    }
   ],
   "source": [
    "#efficiency for training vector\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train_filep= pd.read_json(\"datasets/housing/major_project/TrainingFeatures.json\",lines=True)\n",
    "\n",
    "predicted_ov=[]\n",
    "\n",
    "for i in range(0,len(train_filep),1):\n",
    "    predicted_ov.append(model.predict([[train_filep[\"text_length\"][i],train_filep[\"char_count\"][i],\n",
    "                                        train_filep[\"word_count\"][i],train_filep[\"unique_word_count\"][i],\n",
    "                                       train_filep[\"sent_count\"][i],train_filep[\"ari\"][i],\n",
    "                                       train_filep[\"stars\"][i]]]))    \n",
    "\n",
    "ov_train= pd.read_json(\"datasets/housing/major_project/outcome_variable_train.json\",lines=True)    \n",
    "\n",
    "avg=0\n",
    "for i in range(0,len(ov_train[\"outcome_var\"]),1):\n",
    "    avg+=ov_train[\"outcome_var\"][i]\n",
    "\n",
    "avg= avg/len(ov_train[\"outcome_var\"])\n",
    "\n",
    "print(len(ov_train[\"outcome_var\"]))\n",
    "\n",
    "num=0\n",
    "deno=0\n",
    "\n",
    "for i in range(0,48101,1):\n",
    "    deno+= (ov_train[\"outcome_var\"][i]-avg)**2\n",
    "    \n",
    "for i in range(0,48101,1):\n",
    "    num+= (ov_train[\"outcome_var\"][i]-predicted_ov[i])**2\n",
    "    \n",
    "efficiency = 1-(num/deno)\n",
    "\n",
    "print(efficiency*100 ,\"% for training dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.4806692195 % for testing data\n"
     ]
    }
   ],
   "source": [
    "#efficiency for testing vector\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test_filep= pd.read_json(\"datasets/housing/major_project/TestingFeatures.json\",lines=True)\n",
    "\n",
    "predicted_ov=[]\n",
    "\n",
    "for i in range(0,len(test_filep),1):\n",
    "    predicted_ov.append((model.predict([[test_filep[\"text_length\"][i],test_filep[\"char_count\"][i],\n",
    "                                        test_filep[\"word_count\"][i],test_filep[\"unique_word_count\"][i],\n",
    "                                       test_filep[\"sent_count\"][i],test_filep[\"ari\"][i],\n",
    "                                       test_filep[\"stars\"][i]]]))[0])   \n",
    "\n",
    "ov_test= pd.read_json(\"datasets/housing/major_project/outcome_variable_test.json\",lines=True)    \n",
    "\n",
    "avg=0\n",
    "for i in range(0,len(ov_test[\"outcome_var\"]),1):\n",
    "    avg+=ov_test[\"outcome_var\"][i]\n",
    "\n",
    "avg= avg/len(ov_test[\"outcome_var\"])\n",
    "\n",
    "num=0\n",
    "deno=0\n",
    "\n",
    "for i in range(0,12025,1):\n",
    "    deno+= (ov_test[\"outcome_var\"][i]-avg)**2\n",
    "    \n",
    "for i in range(0,12025,1):\n",
    "    num+= (ov_test[\"outcome_var\"][i]-predicted_ov[i])**2\n",
    "    \n",
    "efficiency =1- (num/deno)\n",
    "\n",
    "print(efficiency*1000, \"% for testing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
